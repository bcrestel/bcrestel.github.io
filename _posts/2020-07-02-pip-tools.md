---
layout: post
title: pip-tools
tags: python dependencies
---

There are a few ways to manage dependencies: conda, poetry, pipenv. I recently
discovered a different way, [pip-tools](https://github.com/jazzband/pip-tools).
It's actually very easy to use and in particular easy to integrate with a docker
image. You simply create a requirements.in file which pip-compile converts to a
requirements.txt file that you can then pip install inside your image by doing
`pip install -r requirements.txt`.

There are multiple comparisons of poetry, pipenv, and pip-tools out there,
including [this one](https://pythonspeed.com/articles/pipenv-docker/) that
compares specifically in the context of combining with docker, and [that
one](https://hynek.me/articles/python-app-deps-2018/#pip-tools--everything-old-is-new-again)
that did a dec 2019 update and still declares pip-tools the winner. I also found
that [blog post](https://alexwlchan.net/2017/10/pip-tools/) useful as it shows
a quick example of how to write a requirements.in.

You can install `pip-tools` through pip, `pip install pip-tools`. The only
things you need to be careful with are the python version and OS you use to
convert you requirements.in file to requirements.txt file. These needs to be the
same as what you'll use for your virtual environment. With Docker, this can be
controlled by applying `pip-tools` inside a running container, then re-building
that image.
