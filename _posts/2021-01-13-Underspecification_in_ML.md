---
layout: post
title: Underspecification in ML
tags: ML deeplearning statistics
---

Researchers at Google published a [paper](https://arxiv.org/pdf/2011.03395.pdf) on the randomness of Deep Learning.
Based on the initial weights, different trained models will be obtained. Theys
show empirically that despite all these models being equivalent during
training, their real-life performance can be dramatically different.

MIT Tech Review published a blog [post](https://www.technologyreview.com/2020/11/18/1012234/training-machine-learning-broken-real-world-heath-nlp-computer-vision/?utm_medium=tr_social&utm_campaign=site_visitor.unpaid.engagement&utm_source=Twitter#Echobox=1609536735) about it
