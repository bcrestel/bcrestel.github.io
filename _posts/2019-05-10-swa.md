---
layout: post
title: Bayesian inference in Deep Learning
tags: deeplearning pytorch optimization bayesian
---

It is possible to perform full-on Bayesian inference in Deep Learning. One could
train a network, assume some sort of Gaussian distribution around the weights
that were found, and the likelihood comes directly from the loss function
since, in general, that loss function is derived from MLE. However, this is
costly, and in practice it's not clear whether people do that or not.

There has been some attempts at using variational inference, i.e., approximating
the posterior with a simpler distribution (e.g., Gaussian), by looking for the
candidate distribution that minimizes the Kullback-Leibler divergence between
the posterior and the candidate distribution. It also seems to be
computationally expensive.

The most popular option is to use Monte-Carlo Dropout (MC Dropout) at inference
time (see [here](https://arxiv.org/pdf/1506.02142.pdf) and
[here](https://www.cs.ox.ac.uk/people/yarin.gal/website/PDFs/DLW_ICML_2015_dropout_bayesian_poster.pdf)).
The idea is to generate samples of the solution of the NN by randomly shutting
down a certain numbers of cells for each forward propagation. The author proves
some interesting properties of their methods.


More recently, Stochastic Weight Averaging (SWA) was introduced (see
[paper](https://arxiv.org/pdf/1803.05407.pdf) and [blog post](https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/)).
