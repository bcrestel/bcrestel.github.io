I"<h2 id="running-a-docker-image">Running a Docker image</h2>

<p><a href="https://www.docker.com/">Docker</a> is way to run a specific application without
having to install it, or compile it and deal with all the dependencies.  In
Ubuntu, it was very easy to install the docker software from the command line.
On Mac, you can look at that <a href="/2018/12/04/setupMac">post</a>.  Once this is done,
you need to identify the image you want to run. A Docker image is a container a
certain set of applications. To run that image, you can type in the command line
<code>docker run &lt;image&gt;</code> If you have never run that image before, the first
time you execute that command, docker will download the image and all other
stuff it needs. If you want to download the image without running it, you can
instead do <code>docker pull &lt;image&gt;</code>.</p>

<p>A few options make the whole Docker experience a lot more useful. In
particular, you typically want that image to be opened in an interactive shell.
For that, you need the options <code>-it</code>. Another useful feature is to be able
to access some folders of your local hard drive from within the image; this can
be done with the option <code>-v LOCAL_FOLDER:DOCKER_FOLDER</code>.</p>

<p>For example, when running the Fenics Docker image, I would do</p>
<pre><code>docker run -t -i -v /home/ben/Work/fenicstools:/home/fenics/fenicstools -v /home/ben/Work/hippylib:/home/fenics/hippylib fenics20171
</code></pre>
<p>to have access to my local <code>fenicstools</code> and <code>hippylib</code> folders.
In another example, to run a tensorflow Docker image, I did</p>
<pre><code>docker run -t -i -v
/home/ben/Work/Programmation/Python/mlds/tensorflow/:/home/tf/
tensorflow/tensorflow bash
</code></pre>
<p>The bash was required here as by default the
<a href="https://www.tensorflow.org/install/docker">tensorflow</a> image starts a notebook.
Actually you start in the <code>/notebook</code> folder, and need to navigate to the
folder you defined <code>cd ../home/tf</code>. But once you figure this out, everything
works great.</p>

<h3 id="running-a-jupyter-notebook-using-a-docker-image">Running a jupyter notebook using a Docker image</h3>

<p>I found the solution in this <a href="https://stackoverflow.com/questions/38830610/access-jupyter-notebook-running-on-docker-container">StackOverflow</a> post. First you need to publish a port of the container to the host (your laptop),</p>
<pre><code>docker run &lt;...&gt; -p 8888:8888 &lt;your_image&gt; bash
</code></pre>
<p>Inside your Docker image, you can start the jupyter notebook,</p>
<pre><code>jupyter-notebook --ip 0.0.0.0 --no-browser --allow-root
</code></pre>
<p>Now on your local machine, from your browser, navigate to <code>localhost:8888/tree</code>. 
You will be prompted with a menu asking for a token. After starting the jupyter notebook, 
you’ll get a http adress which contains the sequence <code>:8888/?token=&lt;...&gt;</code>. 
Your token is made of all the alphanumeric characters following the equal sign.</p>

<h2 id="creating-a-docker-image">Creating a Docker image</h2>
<p>You can save all the characteristics of the image you want to create in a <a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a>, then build the corresponding image by doing, if you’re in the same directory as the Dockerfile,</p>
<pre><code>docker build -t &lt;name&gt;:&lt;tag&gt; .
</code></pre>
<p>For instance <code>docker build -t local/ben:latest .</code>.
You can also specify the modules you want installed in a Pipfile that you load as part of your Docker file, then install with <code>pipenv</code>. In that case, you need to first generate the lock file, then install all the modules. For instance,</p>
<pre><code># Python dependencies
RUN pip install pipenv==2018.11.26
ADD ./Pipfile ./
RUN pipenv lock
RUN pipenv install --system
</code></pre>

<p>Another way to build the image which may be more flexible is to use a <code>docker-compose.yml</code> file 
(see <a href="https://docs.docker.com/compose/overview/">here</a>) and execute it through</p>
<pre><code>docker-compose up &lt;name_specified_in_yml&gt;
</code></pre>
<p>The <code>up</code>, by default will start the container after building and creating it. To prevent this from happening, you can pass the option <code>--no-start</code>.
Note: I had a lot of trouble with <code>docker-compose</code>.</p>

<h2 id="dockerfile-and-absolute-path">Dockerfile and absolute path</h2>
<p>Sometimes you want to create a docker image with files that are in a different
directory. However, you can’t do that with docker. When you define an absolute
path inside your Dockerfile, this refers to the absolute path in the build
context. A work-around is to create your docker image from a place where you can
access (in relative path) all the files you need. And if you want your
Dockerfile to be somewhere else, you can use the <code>-f</code> option,</p>
<pre><code>docker build -f /home/Dockerfile -t mytag .
</code></pre>

<h2 id="pruning-docker">Pruning Docker</h2>
<p>Docker have a very conservative approach to garbage
collection, it seems, and keep everything unless you asked it to delete it. The
problem is that if you’re not careful, you can end up filling up all your
available memory, and you can’t build/pull any images. The solution is to either
(1) increase the amount of memory Docker can use, or (2) prune all the
images/containers/… that you don’t need anymore. To
<a href="https://docs.docker.com/config/pruning/#prune-volumes">prune</a> everything at
one, just do</p>
<pre><code>docker system prune --volumes
</code></pre>
:ET