I"ê<p>Researchers at Google published a <a href="https://arxiv.org/pdf/2011.03395.pdf">paper</a> on the randomness of Deep Learning.
Based on the initial weights, different trained models will be obtained. Theys
show empirically that despite all these models being equivalent during
training, their real-life performance can be dramatically different.</p>

<p>MIT Tech Review published a blog <a href="https://www.technologyreview.com/2020/11/18/1012234/training-machine-learning-broken-real-world-heath-nlp-computer-vision/?utm_medium=tr_social&amp;utm_campaign=site_visitor.unpaid.engagement&amp;utm_source=Twitter#Echobox=1609536735">post</a> about it</p>
:ET